{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.io as spio\n",
    "import sys\n",
    "import numpy as np\n",
    "import TensorFox as tfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadmat(filename):\n",
    "    \"\"\"\n",
    "    This function should be called instead of direct spio.loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects.    \n",
    "    Source: \n",
    "    https://stackoverflow.com/questions/7008608/scipy-io-loadmat-nested-structures-i-e-dictionaries\n",
    "    \"\"\"\n",
    "    \n",
    "    def _check_keys(d):\n",
    "        '''\n",
    "        checks if entries in dictionary are mat-objects. If yes\n",
    "        todict is called to change them to nested dictionaries\n",
    "        '''\n",
    "        for key in d:\n",
    "            if isinstance(d[key], spio.matlab.mio5_params.mat_struct):\n",
    "                d[key] = _todict(d[key])\n",
    "        return d\n",
    "\n",
    "    def _todict(matobj):\n",
    "        '''\n",
    "        A recursive function which constructs from matobjects nested dictionaries\n",
    "        '''\n",
    "        d = {}\n",
    "        for strg in matobj._fieldnames:\n",
    "            elem = matobj.__dict__[strg]\n",
    "            if isinstance(elem, spio.matlab.mio5_params.mat_struct):\n",
    "                d[strg] = _todict(elem)\n",
    "            elif isinstance(elem, np.ndarray):\n",
    "                d[strg] = _tolist(elem)\n",
    "            else:\n",
    "                d[strg] = elem\n",
    "        return d\n",
    "\n",
    "    def _tolist(ndarray):\n",
    "        '''\n",
    "        A recursive function which constructs lists from cellarrays\n",
    "        (which are loaded as numpy ndarrays), recursing into the elements\n",
    "        if they contain matobjects.\n",
    "        '''\n",
    "        elem_list = []\n",
    "        for sub_elem in ndarray:\n",
    "            if isinstance(sub_elem, spio.matlab.mio5_params.mat_struct):\n",
    "                elem_list.append(_todict(sub_elem))\n",
    "            elif isinstance(sub_elem, np.ndarray):\n",
    "                elem_list.append(_tolist(sub_elem))\n",
    "            else:\n",
    "                elem_list.append(sub_elem)\n",
    "        return elem_list\n",
    "    data = scipy.io.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_keys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadstructure(filename):\n",
    "    \"\"\"\n",
    "    This function loads the Matlab structure and converts it to a Python class called 'options',\n",
    "    to be used in Tensor Fox.\n",
    "    \"\"\"\n",
    "    \n",
    "    # The original structure in Matlab must be called 'options'.\n",
    "    try:\n",
    "        opt = loadmat(filename)\n",
    "        options_dict = opt['options']\n",
    "    except FileNotFoundError:\n",
    "        options_dict = {}\n",
    "    \n",
    "    # Create class options for Tensor Fox.\n",
    "    options = False\n",
    "    options = tfx.aux.complete_options(options)\n",
    "\n",
    "    if 'maxiter' in options_dict.keys():\n",
    "        options.maxiter = options_dict['maxiter']\n",
    "    if 'tol' in options_dict.keys():\n",
    "        options.tol = options_dict['tol']\n",
    "        options.method_tol = options_dict['tol']\n",
    "        \n",
    "    if 'method' in options_dict.keys():\n",
    "        options.method = options_dict['method']\n",
    "    if 'method_maxiter' in options_dict.keys():\n",
    "        options.method_maxiter = options_dict['method_maxiter']\n",
    "    if 'method_tol' in options_dict.keys():\n",
    "        options.method_tol = options_dict['method_tol']\n",
    "        \n",
    "    if 'bi_method' in options_dict.keys():\n",
    "        options.bi_method = options_dict['bi_method']\n",
    "    if 'bi_method_maxiter' in options_dict.keys():\n",
    "        options.bi_method_maxiter = options_dict['bi_method_maxiter']\n",
    "    if 'bi_method_tol' in options_dict.keys():\n",
    "        options.bi_method_tol = options_dict['bi_method_tol']    \n",
    "        \n",
    "    if 'initialization' in options_dict.keys():\n",
    "        options.initialization = options_dict['initialization']\n",
    "    if 'trunc_dims' in options_dict.keys():\n",
    "        options.trunc_dims = options_dict['trunc_dims']\n",
    "    if 'mlsvd_tol' in options_dict.keys():\n",
    "        options.mlsvd_tol = options_dict['mlsvd_tol']\n",
    "    if 'init_damp' in options_dict.keys():\n",
    "        options.init_damp = options_dict['init_damp']\n",
    "    if 'refine' in options_dict.keys():\n",
    "        options.refine = options_dict['refine']\n",
    "    if 'symm' in options_dict.keys():\n",
    "        options.symm = options_dict['symm']\n",
    "    if 'low' in options_dict.keys():\n",
    "        options.constraints[0] = options_dict['low']\n",
    "    if 'upp' in options_dict.keys():\n",
    "        options.constraints[1] = options_dict['upp']\n",
    "    if 'constant_norm' in options_dict.keys():\n",
    "        options.constant_norm = options_dict['constant_norm']\n",
    "    if 'factor' in options_dict.keys():\n",
    "        options.constraints[2] = options_dict['factor']\n",
    "    if 'trials' in options_dict.keys():\n",
    "        options.trials = options_dict['trials']\n",
    "    if 'display' in options_dict.keys():\n",
    "        options.display = options_dict['display']\n",
    "    if 'epochs' in options_dict.keys():\n",
    "        options.epochs = options_dict['epochs']\n",
    "        \n",
    "    return options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadarray(filename):\n",
    "    \"\"\"\n",
    "    This functions loads Matlab and Numpy arrays saved in the disk.\n",
    "    \"\"\"\n",
    "    \n",
    "    if filename[-3:] == 'mat':\n",
    "        T_matlab = spio.loadmat('T')\n",
    "        T = T_matlab['T']\n",
    "        return T\n",
    "    else:\n",
    "        try:\n",
    "            T = np.load(filename)\n",
    "            return T\n",
    "        except IOError or ValueError:\n",
    "            sys.exit(\"Error when reading the file '\" + filename + \"'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpd_tfx(tensor_filename, R, options_filename):\n",
    "    \"\"\"\n",
    "    This function prepares all variables saved through Matlab to be used in Tensor Fox. Then in calls the \n",
    "    Tensor Fox CPD function.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load array and options.\n",
    "    T = loadarray(tensor_filename)\n",
    "    options = loadstructure(options_filename)\n",
    "    \n",
    "    # Compute CPD.\n",
    "    factors, T_approx, final_outputs = tfx.cpd(T, R, options)\n",
    "    \n",
    "    # Save factors matrices.\n",
    "    factors_dict = {'factors' : factors}\n",
    "    spio.savemat('factors.mat', factors_dict)\n",
    "    \n",
    "    # Save coordinate tensor.\n",
    "    T_approx_dict = {'T_approx' : T_approx}\n",
    "    spio.savemat('T_approx.mat', T_approx_dict)\n",
    "    \n",
    "   # Save some output information.\n",
    "    output = {}\n",
    "    output['num_steps'] = final_outputs.num_steps\n",
    "    output['rel_error'] = final_outputs.rel_error\n",
    "    output['accuracy'] = max(0, 100*(1 - final_outputs.rel_error))\n",
    "    output['step_sizes'] = final_outputs.step_sizes\n",
    "    output['errors'] = final_outputs.errors\n",
    "    output['improv'] = final_outputs.improv\n",
    "    output['gradients'] = final_outputs.gradients\n",
    "    output['stop'] = final_outputs.stop\n",
    "    spio.savemat('output.mat', output)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 300\n"
     ]
    }
   ],
   "source": [
    "options_filename = 'options.mat'\n",
    "options_tfx = loadstructure(options_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors_dict = {'factors' : factors}\n",
    "spio.savemat('factors.mat', factors_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = np.random.randn(4,5,6)\n",
    "R = 4\n",
    "factors, T_approx, final_outputs = tfx.cpd(T, R, options_tfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = {}\n",
    "w['errors'] = final_outputs.errors\n",
    "spio.savemat('output.mat', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_approx_dict = {'T_approx' : T_approx}\n",
    "spio.savemat('T_approx.mat', T_approx_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save some output information.\n",
    "output = {}\n",
    "output['num_steps'] = final_outputs.num_steps\n",
    "output['rel_error'] = final_outputs.rel_error\n",
    "output['accuracy'] = max(0, 100*(1 - final_outputs.rel_error))\n",
    "output['step_sizes'] = final_outputs.step_sizes\n",
    "output['errors'] = final_outputs.errors\n",
    "output['improv'] = final_outputs.improv\n",
    "output['gradients'] = final_outputs.gradients\n",
    "output['stop'] = final_outputs.stop\n",
    "spio.savemat('output.mat', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.25484132, 1.68064778, 1.13893785, 0.83139969, 0.98346962,\n",
       "        0.78293118, 0.82022338, 0.58983263, 0.43799647, 0.4417889 ,\n",
       "        0.38437406, 0.29425088, 0.24323827, 0.36105202, 0.14941909,\n",
       "        0.06435592, 0.24748629, 0.11453977, 0.06480307, 0.08348535,\n",
       "        0.0606179 , 0.06163824, 0.05131763, 0.20348413, 0.09555731,\n",
       "        0.02263359, 0.27700166, 0.06734041, 0.07542232, 0.22159272,\n",
       "        0.13037597, 0.02677962, 0.02661788, 0.04148248, 0.02737115,\n",
       "        0.02255589, 0.02782585, 0.04528139, 0.01635094, 0.03779272,\n",
       "        0.04017876, 0.03159765, 0.0277028 , 0.08264088, 0.03901652,\n",
       "        0.00777629, 0.0105751 , 0.01388725, 0.00743869, 0.00459698,\n",
       "        0.11407021, 0.03363201, 0.02039067, 0.03382371, 0.04249084,\n",
       "        0.00592471, 0.00981054, 0.04648845, 0.02640107, 0.30288576,\n",
       "        0.04853798, 0.02854244, 0.01363089, 0.01207304, 0.01203851,\n",
       "        0.01004273, 0.00420421]), array([0])]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_outputs.step_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    }
   ],
   "source": [
    "filename = 'options2.mat'\n",
    "try:\n",
    "    opt = loadmat(filename)\n",
    "except FileNotFoundError:\n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {}\n",
    "if 'r' in a.keys():\n",
    "    print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
