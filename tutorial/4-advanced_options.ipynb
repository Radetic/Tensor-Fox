{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced options\n",
    "\n",
    "In the previous lesson we learned about the basic and intermediate options of Tensor Fox. For most of applications this is enough, but sometimes one needs to change more parameters, add constraints, and so on. In this lesson we also cover the options regarding higher order tensors. Warning: this lesson has a more mathematical flavour.\n",
    "\n",
    "Options already covered:\n",
    "\n",
    "    display\n",
    "    maxiter  \n",
    "    tol     \n",
    "    tol_step\n",
    "    tol_improv\n",
    "    tol_grad\n",
    "    tol_mlsvd\n",
    "    trunc_dims\n",
    "    initialization\n",
    "    refine    \n",
    "    init_damp\n",
    "    symm    \n",
    "    tol_jump\n",
    "    \n",
    "Options to be covered:\n",
    "\n",
    "    method\n",
    "    inner_method \n",
    "    cg_maxiter \n",
    "    cg_factor\n",
    "    cg_tol \n",
    "    constraints \n",
    "    trials \n",
    "    bi_method\n",
    "    bi_method_maxiter \n",
    "    bi_method_tol \n",
    "    epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import TensorFox as tfx\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tensor.\n",
    "m = 2\n",
    "T = np.zeros((m, m, m))\n",
    "s = 0\n",
    "\n",
    "for k in range(m):\n",
    "    for i in range(m):\n",
    "        for j in range(m):\n",
    "            T[i,j,k] = s\n",
    "            s += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inner algorithm options\n",
    "\n",
    "The method we are using to solve the problem of tensor approximation is called *damped Gauss-Newton* (dGN), and at each step of this method the program needs to solve a equation of the form\n",
    "\n",
    "$$(J^T J + \\mu D) x = J^Tb$$\n",
    "as already mentioned. To solve this equation we have to rely on other method, which can be an iterative method like the [conjugate gradient](https://en.wikipedia.org/wiki/Conjugate_gradient_method) (default) or a direct method using matrix factorization. The conjugate gradient methods has its own parameters, and the user may have to tune them sometimes. With this in mind, Tensor Fox offers the parameters $\\verb|inner| \\_ \\verb|method|, \\ \\verb|cg| \\_ \\verb|maxiter|, \\ \\verb|cg| \\_ \\verb|tol|$ and $\\verb|cg| \\_ \\verb|factor|$. They are explained below.\n",
    "\n",
    "The inner methods are: $\\verb|cg|, \\ \\verb|cg| \\_ \\verb|static|$, $\\verb|direct|$ and $\\verb|als|$ (alternating least squares, but this one doesn't take in account the regularization). We also mention that it is possible to pass the parameter  $\\verb|inner| \\_ \\verb|method|$ as a list of strings containing the names of the method available. Then the program uses the prescribed sequence of methods, one at each iterarion. We noticed that this hybrid way of work can bring good results sometimes. \n",
    "\n",
    "The difference between static and non-static versions are the way the program deals with the maximum number of iterations. The static algorithm have a certain maximum number of iterations $\\verb|cg| \\_ \\verb|maxiter|$ which is fixed during all the program. The non-static versions uses the parameter $\\verb|cg| \\_ \\verb|factor|$ to control the number of iterations in a different way. If the program is at the $k$-th iteration of the dGN, then the maximum number of iterations permitted for the cg method is\n",
    " \n",
    "$$1 + int\\left( \\verb|cg|\\_\\verb|factor| \\cdot \\verb|randint|\\left( 1 + k^{0.4}, 2 + k^{0.9} \\right) \\right).$$\n",
    "\n",
    "This strange interval of random integers were obtained after a lot of tests, a lot! This seems to be a robust choice, but since we can't be right all the time, the parameter $\\verb|cg| \\_ \\verb|factor|$ comes to the rescue. If the number of maximum iterations are increasing too much, just set this parameter to a low value such as $0.1$ or $0.5$. Finally, the parameter $\\verb|cg| \\_ \\verb|tol|$, as the name suggests, is the tolerance parameter for the cg method. The cg iterations stops when the (absolute) residual is less than $\\verb|cg| \\_ \\verb|tol|$. Below there is an example showing how to setup a method and its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------\n",
      "Computing MLSVD\n",
      "    No compression detected\n",
      "    Working with dimensions (2, 2, 2)\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Type of initialization: random\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Computing CPD\n",
      "    Iteration | Rel error |  Step size  | Improvement | norm(grad) | Predicted error | # Inner iterations\n",
      "        1     | 9.81e-01  |  6.18e-01   |  9.81e-01   |  1.06e+01  |    1.54e-01     |        3        \n",
      "        2     | 8.91e-01  |  2.53e-01   |  9.00e-02   |  7.28e+00  |    2.55e-01     |        3        \n",
      "        3     | 1.86e-01  |  7.15e-01   |  7.05e-01   |  1.28e+01  |    4.38e-02     |        3        \n",
      "        4     | 1.59e-01  |  4.28e-02   |  2.77e-02   |  2.18e+00  |    2.13e-05     |        3        \n",
      "        5     | 1.25e-01  |  8.31e-02   |  3.37e-02   |  1.59e+00  |    8.46e-05     |        3        \n",
      "        6     | 9.65e-02  |  1.27e-01   |  2.86e-02   |  1.05e+00  |    1.45e-04     |        3        \n",
      "        7     | 8.19e-02  |  6.00e-02   |  1.45e-02   |  9.46e-01  |    5.62e-04     |        3        \n",
      "        8     | 6.98e-02  |  2.83e-02   |  1.22e-02   |  1.29e+00  |    3.75e-04     |        3        \n",
      "        9     | 5.22e-02  |  3.70e-02   |  1.76e-02   |  9.70e-01  |    7.32e-04     |        3        \n",
      "       10     | 2.86e-02  |  3.87e-02   |  2.36e-02   |  9.78e-01  |    5.89e-04     |        3        \n",
      "       11     | 9.21e-03  |  2.97e-02   |  1.94e-02   |  8.01e-01  |    1.78e-05     |        3        \n",
      "       12     | 6.81e-03  |  5.36e-03   |  2.40e-03   |  2.00e-01  |    4.96e-06     |        3        \n",
      "       13     | 5.50e-03  |  3.15e-03   |  1.31e-03   |  1.29e-01  |    2.57e-06     |        3        \n",
      "       14     | 4.69e-03  |  2.45e-03   |  8.14e-04   |  8.56e-02  |    1.93e-06     |        3        \n",
      "       15     | 4.02e-03  |  1.71e-03   |  6.72e-04   |  8.41e-02  |    1.27e-06     |        3        \n",
      "       16     | 3.37e-03  |  2.09e-03   |  6.44e-04   |  6.38e-02  |    1.36e-06     |        3        \n",
      "       17     | 2.87e-03  |  1.31e-03   |  5.05e-04   |  6.22e-02  |    8.90e-07     |        3        \n",
      "       18     | 2.48e-03  |  9.73e-04   |  3.89e-04   |  5.20e-02  |    4.46e-07     |        3        \n",
      "       19     | 1.94e-03  |  1.77e-03   |  5.36e-04   |  4.34e-02  |    1.06e-06     |        3        \n",
      "       20     | 4.09e-04  |  4.39e-03   |  1.53e-03   |  3.26e-02  |    9.75e-08     |        3        \n",
      "       21     | 2.19e-04  |  3.98e-04   |  1.90e-04   |  1.28e-02  |    1.38e-08     |        3        \n",
      "       22     | 1.40e-04  |  2.28e-04   |  7.94e-05   |  3.37e-03  |    9.02e-09     |        3        \n",
      "       23     | 6.54e-05  |  2.95e-04   |  7.46e-05   |  3.42e-03  |    2.04e-09     |        3        \n",
      "       24     | 2.71e-05  |  5.88e-05   |  3.83e-05   |  2.09e-03  |    2.17e-10     |        3        \n",
      "       25     | 1.45e-05  |  4.32e-05   |  1.25e-05   |  7.30e-04  |    4.67e-11     |        3        \n",
      "       26     | 8.62e-06  |  1.49e-05   |  5.92e-06   |  4.51e-04  |    3.55e-11     |        3        \n",
      "       27     | 4.05e-06  |  1.38e-05   |  4.57e-06   |  2.39e-04  |    6.45e-12     |        3        \n",
      "       28     | 2.44e-06  |  4.88e-06   |  1.62e-06   |  4.42e-05  |    1.82e-12     |        3        \n",
      "       29     | 1.14e-06  |  5.55e-06   |  1.30e-06   |  3.74e-05  |    5.65e-13     |        3        \n",
      "       30     | 6.75e-07  |  1.20e-06   |  4.65e-07   |  2.24e-05  |    9.28e-14     |        3        \n",
      "       31     | 5.18e-07  |  6.21e-07   |  1.57e-07   |  1.12e-05  |    6.67e-14     |        3        \n",
      "       32     | 1.52e-07  |  1.15e-06   |  3.66e-07   |  8.14e-06  |    1.57e-14     |        3        \n",
      "       33     | 8.29e-08  |  1.30e-07   |  6.86e-08   |  4.39e-06  |    1.06e-15     |        3        \n",
      "       34     | 4.98e-08  |  9.42e-08   |  3.31e-08   |  1.16e-06  |    6.10e-16     |        3        \n",
      "       35     | 3.53e-08  |  4.28e-08   |  1.45e-08   |  7.83e-07  |    4.03e-16     |        3        \n",
      "       36     | 7.55e-09  |  7.99e-08   |  2.78e-08   |  6.35e-07  |    3.22e-17     |        3        \n",
      "       37     | 4.46e-09  |  8.18e-09   |  3.09e-09   |  1.68e-07  |    3.72e-18     |        3        \n",
      "       38     | 3.35e-09  |  3.27e-09   |  1.11e-09   |  6.49e-08  |    2.72e-18     |        3        \n",
      "       39     | 1.05e-09  |  7.02e-09   |  2.30e-09   |  5.44e-08  |    1.04e-18     |        3        \n",
      "       40     | 2.19e-10  |  2.05e-09   |  8.33e-10   |  3.41e-08  |    2.66e-20     |        3        \n",
      "       41     | 6.67e-11  |  2.69e-10   |  1.52e-10   |  5.72e-09  |    6.74e-22     |        3        \n",
      "       42     | 5.52e-11  |  3.46e-11   |  1.16e-11   |  9.82e-10  |    2.11e-22     |        3        \n",
      "       43     | 3.69e-11  |  6.12e-11   |  1.82e-11   |  1.01e-09  |    4.12e-22     |        3        \n",
      "       44     | 1.90e-11  |  5.54e-11   |  1.79e-11   |  5.57e-10  |    2.11e-22     |        3        \n",
      "       45     | 1.12e-11  |  2.13e-11   |  7.87e-12   |  4.54e-10  |    2.55e-23     |        3        \n",
      "       46     | 8.69e-12  |  6.02e-12   |  2.47e-12   |  1.76e-10  |    1.42e-23     |        3        \n",
      "       47     | 5.47e-12  |  1.13e-11   |  3.22e-12   |  1.42e-10  |    1.93e-23     |        3        \n",
      "       48     | 6.43e-13  |  1.20e-11   |  4.83e-12   |  1.53e-10  |    2.95e-25     |        3        \n",
      "       49     | 2.44e-13  |  9.07e-13   |  3.99e-13   |  1.04e-11  |    3.39e-26     |        3        \n",
      "       50     | 1.09e-13  |  4.50e-13   |  1.35e-13   |  3.53e-12  |    7.64e-27     |        3        \n",
      "       51     | 6.10e-14  |  8.43e-14   |  4.81e-14   |  3.26e-12  |    6.28e-28     |        3        \n",
      "       52     | 4.81e-14  |  3.49e-14   |  1.29e-14   |  7.97e-13  |    2.92e-28     |        3        \n",
      "       53     | 4.10e-14  |  2.01e-14   |  7.13e-15   |  7.99e-13  |    1.82e-28     |        3        \n",
      "       54     | 3.54e-14  |  1.53e-14   |  5.57e-15   |  6.83e-13  |    9.42e-29     |        3        \n",
      "       55     | 2.87e-14  |  2.37e-14   |  6.70e-15   |  6.01e-13  |    1.69e-28     |        3        \n",
      "       56     | 1.23e-14  |  5.38e-14   |  1.64e-14   |  5.12e-13  |    1.44e-28     |        3        \n",
      "       57     | 4.03e-15  |  1.85e-14   |  8.31e-15   |  3.91e-13  |    1.30e-29     |        3        \n",
      "       58     | 2.07e-15  |  4.69e-15   |  1.95e-15   |  7.64e-14  |    8.77e-31     |        3        \n",
      "       59     | 1.35e-15  |  2.97e-15   |  7.24e-16   |  6.61e-14  |    1.05e-30     |        3        \n",
      "       60     | 8.01e-16  |  9.69e-16   |  5.49e-16   |  4.97e-14  |    1.85e-31     |        3        \n",
      "       61     | 6.06e-16  |  2.45e-15   |  1.96e-16   |  1.78e-14  |    3.92e-31     |        3        \n",
      "       62     | 3.48e-16  |  1.07e-15   |  2.58e-16   |  2.66e-14  |    1.49e-31     |        3        \n",
      "       63     | 6.94e-16  |  1.76e-15   |  3.46e-16   |  7.99e-15  |    4.41e-31     |        3        \n",
      "       64     | 8.16e-16  |  1.42e-15   |  1.22e-16   |  2.51e-14  |    5.43e-32     |        3        \n",
      "       65     | 7.71e-16  |  1.27e-15   |  4.42e-17   |  4.97e-14  |    2.92e-31     |        3        \n",
      "       66     | 5.88e-16  |  1.38e-15   |  1.83e-16   |  3.66e-14  |    2.79e-31     |        3        \n",
      "       67     | 6.18e-16  |  1.64e-15   |  3.01e-17   |  2.42e-14  |    1.79e-31     |        3        \n",
      "       68     | 7.22e-16  |  2.36e-15   |  1.04e-16   |  4.26e-14  |    3.94e-31     |        3        \n",
      "       69     | 2.24e-16  |  1.21e-15   |  4.98e-16   |  2.13e-14  |    7.81e-32     |        3        \n",
      "       70     | 5.06e-16  |  7.80e-16   |  2.82e-16   |  1.42e-14  |    2.38e-31     |        3        \n",
      "       71     | 6.49e-16  |  2.54e-15   |  1.43e-16   |  2.13e-14  |    4.07e-31     |        3        \n",
      "       72     | 1.93e-16  |  8.56e-16   |  4.56e-16   |  2.13e-14  |    1.30e-31     |        3        \n",
      "       73     | 1.83e-16  |  5.79e-16   |  1.01e-17   |  1.09e-14  |    5.00e-32     |        3        \n",
      "       74     | 5.23e-16  |  1.01e-15   |  3.40e-16   |  7.11e-15  |    1.76e-31     |        3        \n",
      "       75     | 4.80e-16  |  1.64e-15   |  4.32e-17   |  1.42e-14  |    2.66e-31     |        3        \n",
      "       76     | 6.29e-16  |  1.35e-15   |  1.48e-16   |  1.67e-14  |    3.29e-31     |        3        \n",
      "       77     | 2.16e-16  |  9.29e-16   |  4.12e-16   |  1.49e-14  |    2.18e-32     |        3        \n",
      "       78     | 3.94e-16  |  1.72e-15   |  1.78e-16   |  1.42e-14  |    2.84e-31     |        3        \n",
      "       79     | 4.70e-16  |  7.88e-16   |  7.62e-17   |  7.11e-15  |    1.15e-31     |        3        \n",
      "       80     | 1.64e-15  |  5.28e-15   |  1.16e-15   |  2.84e-14  |    1.18e-30     |        3        \n",
      "       81     | 5.57e-16  |  1.79e-15   |  1.08e-15   |  4.44e-14  |    1.53e-31     |        3        \n",
      "       82     | 4.56e-16  |  1.39e-15   |  1.01e-16   |  2.13e-14  |    3.21e-31     |        3        \n",
      "       83     | 1.04e-15  |  1.84e-15   |  5.88e-16   |  1.12e-14  |    7.08e-31     |        3        \n",
      "       84     | 9.08e-16  |  1.45e-15   |  1.36e-16   |  4.26e-14  |    2.74e-31     |        3        \n",
      "       85     | 4.76e-16  |  8.40e-16   |  4.32e-16   |  4.26e-14  |    5.42e-32     |        3        \n",
      "       86     | 7.08e-16  |  1.34e-15   |  2.32e-16   |  2.13e-14  |    5.37e-31     |        3        \n",
      "       87     | 4.09e-16  |  8.62e-16   |  2.99e-16   |  2.40e-14  |    6.16e-32     |        3        \n",
      "       88     | 4.92e-16  |  6.14e-16   |  8.31e-17   |  2.13e-14  |    5.41e-32     |        3        \n",
      "       89     | 1.90e-15  |  5.99e-15   |  1.40e-15   |  3.55e-14  |    3.13e-30     |        3        \n",
      "       90     | 5.70e-16  |  2.12e-15   |  1.33e-15   |  7.29e-14  |    1.27e-31     |        3        \n",
      "       91     | 7.82e-16  |  2.08e-15   |  2.12e-16   |  2.84e-14  |    3.31e-31     |        3        \n",
      "       92     | 2.71e-16  |  1.02e-15   |  5.11e-16   |  2.84e-14  |    6.00e-32     |        3        \n",
      "       93     | 2.22e-16  |  3.26e-16   |  4.86e-17   |  7.11e-15  |    5.84e-32     |        3        \n",
      "       94     | 1.78e-16  |  3.08e-16   |  4.42e-17   |  7.11e-15  |    7.12e-32     |        3        \n",
      "       95     | 6.79e-16  |  1.37e-15   |  5.01e-16   |  2.84e-14  |    2.90e-31     |        3        \n",
      "       96     | 3.54e-15  |  1.33e-14   |  2.86e-15   |  2.95e-14  |    6.78e-30     |        3        \n",
      "       97     | 2.11e-16  |  2.60e-15   |  3.33e-15   |  1.49e-13  |    2.25e-32     |        3        \n",
      "       98     | 5.35e-16  |  7.89e-16   |  3.25e-16   |  1.42e-14  |    2.63e-32     |        3        \n",
      "       99     | 4.92e-16  |  1.84e-15   |  4.37e-17   |  2.13e-14  |    1.81e-31     |        3        \n",
      "       100    | 2.47e-16  |  1.11e-15   |  2.44e-16   |  1.42e-14  |    1.11e-31     |        3        \n",
      "       101    | 3.30e-16  |  3.98e-16   |  8.23e-17   |  1.42e-14  |    4.26e-32     |        3        \n",
      "       102    | 1.80e-15  |  6.53e-15   |  1.47e-15   |  4.26e-14  |    2.61e-30     |        3        \n",
      "       103    | 5.02e-16  |  1.56e-15   |  1.30e-15   |  5.46e-14  |    1.32e-31     |        3        \n",
      "       104    | 3.12e-16  |  8.39e-16   |  1.90e-16   |  9.55e-15  |    4.90e-32     |        3        \n",
      "       105    | 3.05e-16  |  8.00e-16   |  7.22e-18   |  1.42e-14  |    1.29e-31     |        3        \n",
      "       106    | 3.64e-16  |  4.75e-16   |  5.97e-17   |  1.42e-14  |    1.37e-31     |        3        \n",
      "===============================================================================================\n",
      "Final results\n",
      "    Number of steps = 106\n",
      "    Relative error = 6.7584358465908725e-16\n",
      "    Accuracy =  100.0 %\n"
     ]
    }
   ],
   "source": [
    "# Let's use cg_static as the inner algorithm, with 3 iteratins max and tolerance of 1e-7.\n",
    "class options:\n",
    "    inner_method = 'cg_static'\n",
    "    cg_maxiter = 3\n",
    "    cg_tol = 1e-7\n",
    "    display = 2\n",
    "\n",
    "R = 3\n",
    "factors, output = tfx.cpd(T, R, options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constraints\n",
    "\n",
    "The parameter $\\verb|factors| \\_ \\verb|norm|$ is used to fix the norm of the factor matrices of the CPD. Suppose $T$ is a third tensor and $(X^{(k)}, Y^{(k)}, Z^{(k)})$ the approximated CPD at iteration $k$. If one set $\\verb|factors| \\_ \\verb|norm| = 2$, for example, then $\\| X^{(k)} \\| = \\| Y^{(k)} \\| = \\| Z^{(k)} \\| = 2$ for all $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Higher order tensors and the Tensor Train format\n",
    "\n",
    "Tensor Fox has distinct approaches when it comes to computing the CPD of third order tensors and higher order tensors. For third order tensors the program relies on the *Damped Gauss-Newton* (dGN) method. For higher order tensors the program relies on the *Tensor Train format* (TT format), also called *Tensor Train decomposition*. Without going in too much details, we use a specific configuration of the TT format which can be obtained by computing several third order CPD's. More precisely, if $T$ is a tensor of order $L$, then we can compute a CPD for it by computing $L-2$ third order CPD's. Once we have the TT format of $T$, the CPD can also be computed. The figure below illustrate the representation of a tensor train associated to a tensor of order $L$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tensortrain](tensor-train.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each square represent the coordinates of a tensor and each circle is the coordinate with is shared between two consecutive tensors. These tensors are usually denoted by $\\mathcal{G}^{(\\ell)}$. For example, the second tensor is $\\mathcal{G}^{(2)}$, which has coordinates $\\mathcal{G}^{(\\ell)}_{j_1 i_2 j_2}$, and the next tensor is $\\mathcal{G}^{(3)}$, which has coordinates $\\mathcal{G}^{(\\ell)}_{j_2 i_3 j_3}$. The first and last tensor are acutally matrices (which mean $j_0 = j_L = 1$), and the other $L-2$ tensor are third order tensors. They are related to $T$ by the following formula:\n",
    "$$T_{i_1 i_2 \\ldots i_L} = \\sum_{j_0, j_1, \\ldots, j_L} \\mathcal{G}^{(1)}_{j_0 i_1 j_1} \\cdot \\mathcal{G}^{(2)}_{j_1 i_2 j_2} \\cdot \\ldots \\cdot \\mathcal{G}^{(L)}_{j_{L-1} i_L j_L}.$$\n",
    "\n",
    "By computing a CPD for $\\mathcal{G}^{(2)}, \\ldots, \\mathcal{G}^{(L-1)}$ we can obtain a CPD for $T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trials\n",
    "\n",
    "In the case $T$ has order higher than $3$, the parameter $\\verb|trials|$ defines how much times we compute each one of these third order CPD's. The idea is to compute several times and keep the best result (smaller error). This may be helpful because all $L-2$ CPD's needs to be of good quality in order to get a good CPD for $T$. If just one of the third order CPD's has bad precision, than everything falls apart. Currently the default is $\\verb|trials|= 3$, but this may change depending on the problem. This parameter doesn't makes difference if $T$ is a third order tensor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display\n",
    "\n",
    "As we've said, the options $\\verb|trials|$ says about the repetition of third order CPD computations. If $\\verb|display|$ is set to $1, 2, 3$ or $4$, then all the information of each one of these CPD's are printed on the screen. This means we wil have $(L-2) \\cdot \\verb|trials|$ CPD's informations printed on the screen when $T$ has order $L$ . Sometimes this amount of information is just too much. We can make everything more succint in these situations just by setting $\\verb|display| =-1$. Consider the following fourth order tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = \n",
      "[[[[-0.24735599 -0.02183084  0.40427194]\n",
      "   [-0.10145421 -0.02493161  0.12757709]\n",
      "   [-0.09294855 -0.04450633  0.06503369]]\n",
      "\n",
      "  [[ 0.07937422  0.01831296 -0.10266607]\n",
      "   [ 0.01644555 -0.00557181 -0.04368592]\n",
      "   [-0.00677789 -0.02284462 -0.04216168]]\n",
      "\n",
      "  [[ 0.4294738   0.06303212 -0.64178466]\n",
      "   [ 0.14035026  0.01312734 -0.22761258]\n",
      "   [ 0.08003979 -0.00522857 -0.1602331 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.16211098  0.14940549  0.0583617 ]\n",
      "   [-0.12598556 -0.14581353 -0.11643811]\n",
      "   [-0.37641272 -0.41439806 -0.29701936]]\n",
      "\n",
      "  [[ 0.08419917  0.0986208   0.08061867]\n",
      "   [-0.09538447 -0.10096481 -0.06558483]\n",
      "   [-0.26355255 -0.28425237 -0.19385288]]\n",
      "\n",
      "  [[ 0.0212432   0.06629116  0.11943927]\n",
      "   [-0.0830618  -0.07517527 -0.02660886]\n",
      "   [-0.20054084 -0.20767522 -0.12688495]]]\n",
      "\n",
      "\n",
      " [[[ 0.04034607  0.05578837  0.05904842]\n",
      "   [-0.05786119 -0.05862016 -0.0334997 ]\n",
      "   [-0.15390614 -0.16421888 -0.10895525]]\n",
      "\n",
      "  [[ 0.03971423  0.03977858  0.02190054]\n",
      "   [-0.03539043 -0.03953484 -0.02929718]\n",
      "   [-0.10249846 -0.11195086 -0.07874674]]\n",
      "\n",
      "  [[ 0.0469733   0.03131627 -0.01174838]\n",
      "   [-0.01944395 -0.02787723 -0.03082922]\n",
      "   [-0.0703033  -0.08075703 -0.0635138 ]]]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize dimensions of the tensor.\n",
    "k = 2\n",
    "dims = (k+1, k+1, k+1, k+1)\n",
    "L = len(dims)\n",
    "\n",
    "# Create four random factors matrices so that\n",
    "# A = (orig_factors[0], orig_factors[1], orig_factors[2], orig_factors[3])*I.\n",
    "orig_factors = []\n",
    "for l in range(L):\n",
    "    M = np.random.randn(dims[l], k)\n",
    "    Q, R = np.linalg.qr(M)\n",
    "    orig_factors.append(Q)\n",
    "    \n",
    "# From the factor matrices generate the respective tensor in coordinates.\n",
    "A = tfx.cpd2tens(orig_factors)\n",
    "\n",
    "print('A = ')\n",
    "tfx.showtens(A) # now this is the same as print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------\n",
      "Computing MLSVD\n",
      "    Compression detected\n",
      "    Compressing from (3, 3, 3, 3) to (2, 2, 2, 2)\n",
      "\n",
      "Total of 2 third order CPDs to be computed:\n",
      "===============================================================================================\n",
      "CPD 1 error = 3.494337683655528e-16\n",
      "CPD 2 error = 6.804363002006075e-16\n",
      "\n",
      "===============================================================================================\n",
      "===============================================================================================\n",
      "Final results\n",
      "    Number of steps = 109\n",
      "    Relative error = 1.0796122665438574e-15\n",
      "    Accuracy =  100.0 %\n"
     ]
    }
   ],
   "source": [
    "# Compute the CPD of A with succint display for higher order tensors.\n",
    "class options:\n",
    "    display = -1\n",
    "    \n",
    "factors, output = tfx.cpd(A, k, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------\n",
      "Computing MLSVD\n",
      "    Compression detected\n",
      "    Compressing from (3, 3, 3, 3) to (2, 2, 2, 2)\n",
      "    Compression relative error = 8.475312e-16\n",
      "\n",
      "===============================================================================================\n",
      "SVD Tensor train error =  1.0657924193761152e-15\n",
      "===============================================================================================\n",
      "\n",
      "Total of 2 third order CPDs to be computed:\n",
      "===============================================================================================\n",
      "CPD 1 error = 4.4278625581494807e-16\n",
      "CPD 2 error = 1.836068564802365e-15\n",
      "\n",
      "===============================================================================================\n",
      "CPD Tensor train error =  1.109450470070002\n",
      "===============================================================================================\n",
      "\n",
      "===============================================================================================\n",
      "===============================================================================================\n",
      "Final results\n",
      "    Number of steps = 130\n",
      "    Relative error = 1.967941906948239e-15\n",
      "    Accuracy =  100.0 %\n"
     ]
    }
   ],
   "source": [
    "# The options display = -2 is showed below. \n",
    "options.display = -2\n",
    "factors, output = tfx.cpd(A, k, options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLSVD tolerance with high order tensors\n",
    "\n",
    "Now let's see what happens when we set $\\verb|tol| \\_ \\verb|mlsvd| = [\\verb|1e-6|, \\verb|-1|]$ for the tensor $A$. This choice means the program will perform the high order compression using $10^{-6}$ as tolerance, and will not compress the intermediate third order tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------\n",
      "Computing MLSVD\n",
      "    Compression detected\n",
      "    Compressing from (3, 3, 3, 3) to (2, 2, 2, 2)\n",
      "    Compression relative error = 8.475312e-16\n",
      "\n",
      "===============================================================================================\n",
      "SVD Tensor train error =  1.0657924193761152e-15\n",
      "===============================================================================================\n",
      "\n",
      "Total of 2 third order CPDs to be computed:\n",
      "===============================================================================================\n",
      "CPD 1 error = 1.1274368112207335e-16\n",
      "CPD 2 error = 3.359456723059429e-16\n",
      "\n",
      "===============================================================================================\n",
      "CPD Tensor train error =  3.188348304649288\n",
      "===============================================================================================\n",
      "\n",
      "===============================================================================================\n",
      "===============================================================================================\n",
      "Final results\n",
      "    Number of steps = 172\n",
      "    Relative error = 1.0560021407128175e-15\n",
      "    Accuracy =  100.0 %\n"
     ]
    }
   ],
   "source": [
    "options.tol_mlsvd = [1e-6, -1]\n",
    "factors, output = tfx.cpd(A, k, options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner algorithm options\n",
    "\n",
    "Just as usual third order tensors has the options $\\verb|method|, \\verb|tol|, \\verb|maxiter|$ for its inner computations, the third order tensors of a tensor train also can receive these parameters. However there is a difference here: when computing the CPD's of each $\\mathcal{G}^{(\\ell)}$, the program starts computing the CPD of $\\mathcal{G}^{(2)}$, and one factor is of the CPD is used to compute the CPD of $\\mathcal{G}^{(3)}$. Then one factor of this CPD is used to compute the CPD of $\\mathcal{G}^{(4)}$ and so on. In short, each CPD depends on the previous computed CPD. The matrices $\\mathcal{G}^{(1)}$ and $\\mathcal{G}^{(L)}$ are easily computed after we have the other CPD's.\n",
    "\n",
    "The first CPD can be computed as any CPD, but the other always depends on some previous computed factor, which is always used to fix one factor of the next CPD. This means each CPD, except the first, is actually only computing two factors, so there is a difference in how the program computes the first CPD and the remaining ones. Therefore, the parameters $\\verb|method|, \\ \\verb|method| \\_ \\verb|tol|, \\ \\verb|method| \\_ \\verb|maxiter|$ are used for the first CPD and the parameters $\\verb|bi| \\_ \\verb|method|, \\ \\verb|bi| \\_ \\verb|method| \\_ \\verb|tol|, \\ \\verb|bi| \\_ \\verb|method| \\_ \\verb|maxiter|$ are used for all the remaining CPD's. The figure below illustrate these observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tensortrainmethods](tensor-train-methods.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epochs\n",
    "\n",
    "As we can note, there is a flow of information in the tensor train format, the CPD's are computed from left to right, and the next CPD always depend on some information about the previous CPD. Once we compute the CPD of $\\mathcal{G}^{(L-1)}$ it is possible to \"go back\", that is, use the information of the CPD of $\\mathcal{G}^{(L-1)}$ to compute a new CPD for $\\mathcal{G}^{(L-2)}$, we just have to reverse the way information is propagated. Doing this we may be able to refine all CPD's. These cycles can repeated several times, with the information being propagated forward and backward again and again. Each cycle is called an *epoch*, and the number of epochs can be passed to the program through the parameter $\\verb|epochs|$. Below we redefine the tensor $A$ to have a higher order and try to refine the CPD by using more epochs than just $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------\n",
      "Computing MLSVD\n",
      "    Compression detected\n",
      "    Compressing from (3, 3, 3, 3, 3, 3) to (2, 2, 2, 2, 2, 2)\n",
      "\n",
      "Total of 4 third order CPDs to be computed:\n",
      "===============================================================================================\n",
      "CPD 1 error = 1.045637829722678e-15\n",
      "CPD 2 error = 1.0190147433486697e-15\n",
      "CPD 3 error = 4.629079610866341e-16\n",
      "CPD 4 error = 1.0799848371367143e-15\n",
      "\n",
      "===============================================================================================\n",
      "===============================================================================================\n",
      "Final results\n",
      "    Number of steps = 199\n",
      "    Relative error = 2.6255154394559685e-15\n",
      "    Accuracy =  100.0 %\n"
     ]
    }
   ],
   "source": [
    "# Initialize the sixth-order tensor and compute its CPD with default options.\n",
    "k = 2\n",
    "dims = (k+1, k+1, k+1, k+1, k+1, k+1)\n",
    "L = len(dims)\n",
    "\n",
    "orig_factors = []\n",
    "for l in range(L):\n",
    "    M = np.random.randn(dims[l], k)\n",
    "    Q, R = np.linalg.qr(M)\n",
    "    orig_factors.append(Q)\n",
    "    \n",
    "A = tfx.cpd2tens(orig_factors)\n",
    "\n",
    "class options:\n",
    "    display = -1\n",
    "    \n",
    "factors, output = tfx.cpd(A, k, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------\n",
      "Computing MLSVD\n",
      "    Compression detected\n",
      "    Compressing from (3, 3, 3, 3, 3, 3) to (2, 2, 2, 2, 2, 2)\n",
      "\n",
      "Total of 4 third order CPDs to be computed:\n",
      "===============================================================================================\n",
      "Epoch  1\n",
      "CPD 1 error = 1.0893267320882904e-15\n",
      "CPD 2 error = 9.598842394440558e-16\n",
      "CPD 3 error = 4.2607859765869694e-16\n",
      "CPD 4 error = 9.990079565155955e-16\n",
      "\n",
      "Epoch  2\n",
      "CPD 3 error = 7.373533910551415e-16\n",
      "CPD 2 error = 1.0763085776979368e-15\n",
      "CPD 1 error = 9.953608301111264e-16\n",
      "\n",
      "Epoch  3\n",
      "CPD 2 error = 6.939188515085048e-16\n",
      "CPD 3 error = 4.725840149391478e-16\n",
      "CPD 4 error = 1.0381475795276401e-15\n",
      "\n",
      "Epoch  4\n",
      "CPD 3 error = 4.968218961534697e-16\n",
      "CPD 2 error = 8.65495724415512e-16\n",
      "CPD 1 error = 9.711669382244872e-16\n",
      "\n",
      "Epoch  5\n",
      "CPD 2 error = 7.796832691071586e-16\n",
      "CPD 3 error = 4.1462431388048813e-16\n",
      "CPD 4 error = 1.0634067147480643e-15\n",
      "\n",
      "===============================================================================================\n",
      "===============================================================================================\n",
      "Final results\n",
      "    Number of steps = 12\n",
      "    Relative error = 2.203927892406908e-15\n",
      "    Accuracy =  100.0 %\n"
     ]
    }
   ],
   "source": [
    "# Now we use 5 epochs on the same tensor.\n",
    "options.epochs = 5\n",
    "options.display = -1\n",
    "factors, output = tfx.cpd(A, k, options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method\n",
    "\n",
    "The last parameter to be seen is $\\verb|method|$. By default Tensor Fox uses $\\verb|method| = \\verb|'dGN'|$, which means the program will use the damped Gauss-Newton method. This is true for third order tensors, but not for higher order tensors, where the Tensor Train CPD method is used by default. It is also possible to set $\\verb|method| = \\verb|'ttcpd'|$ for third order tensors, then the program uses the Tensor Train CPD for a thir order tensor. Other possibilitie is $\\verb|'als'|$ (Alternating Least Squares). By setting $\\verb|'dGN'|$ explicitly the program will use the dGN method for higher order tensors)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
