{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First things first\n",
    "\n",
    "Welcome to our very first introduction to *Tensor Fox*, a specialized library made to deal with tensors of any order with focus on the CPD (Canonical Polyadic Decomposition). In order to have everything working properly, all files of Tensor Fox must be in the same folder of your program. To be able to use Tensor Fox properly you will need the following modules:\n",
    "\n",
    "- numpy\n",
    "\n",
    "- pandas\n",
    "\n",
    "- scipy\n",
    "\n",
    "- sklearn\n",
    "\n",
    "- matplotlib\n",
    "\n",
    "- numba\n",
    "\n",
    "Make sure Numba and Numpy updated. Additionaly, make sure you are using a nice BLAS version. That is all! Tensor Fox is read to go! Let's start importing Tensor Fox and other necessary modules for this first lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import TensorFox as tfx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and knowing your tensor\n",
    "\n",
    "Let's create a little tensor $T$ just to see how Tensor Fox works at its basics. For third order tensors (3D arrays) I use the convention that $T_{ijk}$ refers to the $i$-th row, $j$-column and $k$-slice (frontal slice) of $T$. For instance, consider the tensor defined above (the frontal slices of $T$ are showed)\n",
    "\n",
    "$$T = \\left\\{ \\left[\n",
    "\\begin{array}{cc}\n",
    "    0 & 1\\\\\n",
    "    2 & 3\n",
    "\\end{array}\n",
    "\\right], \\quad\n",
    "\\left[\n",
    "\\begin{array}{cc}\n",
    "    4 & 5\\\\\n",
    "    6 & 7\n",
    "\\end{array}\n",
    "\\right] \\right\\}.$$\n",
    "\n",
    "Since Numpy's convention is different from ours with regard to third order tensors. This convention may be irrelevant when using the routines of Tensor Fox, but since I build all the modules thinking this way, it is fair that this point is made explicitly. The function **showtens** prints a third order tensor with this particular convention and print tensors of higher order just as Numpy would print. Below we show both conventions with an example of third order tensor. This particular tensor will be our toy model through all lessons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Fox view of T:\n",
      "---------------------\n",
      "[[0. 1.]\n",
      " [2. 3.]]\n",
      "\n",
      "[[4. 5.]\n",
      " [6. 7.]]\n",
      "\n",
      "\n",
      "Numpy view of T:\n",
      "----------------\n",
      "[[[0. 4.]\n",
      "  [1. 5.]]\n",
      "\n",
      " [[2. 6.]\n",
      "  [3. 7.]]]\n"
     ]
    }
   ],
   "source": [
    "# Create and print the tensor, which is 2 x 2 x 2.\n",
    "m = 2\n",
    "T = np.zeros((m, m, m))\n",
    "s = 0\n",
    "\n",
    "for k in range(m):\n",
    "    for i in range(m):\n",
    "        for j in range(m):\n",
    "            T[i,j,k] = s\n",
    "            s += 1\n",
    "\n",
    "print('Tensor Fox view of T:')\n",
    "print('---------------------')          \n",
    "tfx.disp.showtens(T)\n",
    "print()\n",
    "print('Numpy view of T:')\n",
    "print('----------------')\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of questions we can make about a given tensor $T$. What are its maximum and minimum entries, what are the dimensions of $T$, the rank and multirank, etc. Even in the case of the simple tensor above we can't know all these answers in advance. The function **infotens** shows lots of information about $T$ for your convenience. This function is useful for small tensors, but remember that finding the rank is a NP-hard task, so don't abuse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T is a tensor of dimensions (2, 2, 2)\n",
      "\n",
      "|T| = 11.832159566199232\n",
      "\n",
      "max(T) = 7.0\n",
      "\n",
      "min(T) = 0.0\n",
      "\n",
      "mean(T) = 3.5\n",
      "\n",
      "mean(|T|) = 3.5\n",
      "\n",
      "var(T) = 5.25\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAYM0lEQVR4nO3de7gddX3v8feHhBhQkZbEyyHB4DFeIl5iI2qx1goqKMLxSBVaxFIVW8XLscc+2FOlolXUCkcsghz0iKhEES/RE0QRb7WiBBHkIm1AKDEiwYKIohD8nj/WbF1s1t57kezZa+/M+/U8ebLmN7+Z+a5NWJ+9fjPzm1QVkqTu2m7UBUiSRssgkKSOMwgkqeMMAknqOINAkjrOIJCkjjMIpCElWZikkiyZYP1LknxupuuStla8j0CjkOTWvsUdgV8DdzbLL6+qj858VZNLshC4DVhaVRu2Yj+rgUur6q3TVpy0FeaPugB1U1XdZ+x1kmuAl1bVuaOr6K6SzK+qzaOu456aq3VrtBwa0qyUZF6SNya5OsmNST6aZOdm3SOSbE5yeJINSTYleX3ftnsluSjJLUmuT/L2vnXPT3J5kpuTnJtked+665P8zySXAbdMUt5+Sa5KclOS4/u2/6sk5/bV/89NbT9LcnGShyd5NfB84I1Jbk1yZtP/0Um+0dR1SZL9+vZ7/yRnN+/n/CTH9h1nbLjqr5NcBVzatJ/U/GxuSfKdJE/q29+xzc/z400N30uye5Kjm5/1NUn+ZAv/02kOMgg0W70eeCbwFGAJcAdwfN/6ecAq4KHAs4F/TPKQZt0/A2+rqp2A5cBnAJLsAXwIeAVwf+BrwJok/d+MXwg8A9hlktr2A1YCjwcOT/K0AX32B/4A+K/A7wF/BtxUVScAZwFvqar7VNWfNkNOn2/qXNy89zOT7N7s6xRgE/AA4AjgxZMcb2Wz/C3g0c37+Gyzv+37+j8POBnYGbgSOA/4BfBA4N3A+yZ5/9rGGASarV4OHFVVG6vqV8CbgRcmSV+fo6vqV1V1AfAD4DFN+x3Aw5LsUlU/r6pvN+2HAJ+uqq9W1e3A24BF9AJlzPHNMW+bpLa3VdUtVfVD4OvA4wb0uQPYCXgEUFV1WVXdMMH+/qj5+7iquqOqzgG+1LzfhcABwBur6raqugQYdP7kH6vq5rG6q+rDVXVTVd3RvM9dgIf09f9yVX2lGUb6ZFPru5vl1cAjkuwwyc9A2xCDQLNO82G/FFjbDJXcDFxE79/r2G/qd1bVjX2b/RIYO+/wYnqh8G9Jvp3kWU37fwGuHdugqu4EfgTs2ref64Yo8foJjtvvbOADwPuBnyR5X5JB/cbq+o+665Ub1zZ1PRAI0H9yelCNd2lL8oYkVyb5GXATsJBe6I35Sd/r24BNfccfC8F7T1CvtjEGgWad5gPpR8DTq2rnvj8Lx334T7T9FVX1QnrDPycAn0qyANgIPHisX5J59D5sf9S/+XS9h6o6rqpW0gulxwKvmeAYG4HdxrXt1tR1fdO/P6yWDjrk2IskzwBeRW/4Z2fg9+l9uGfAdpJBoFnrZODYJEvhtydMnzvMhkkOa4aF7gR+Ru9D8jfAx4HnJXlqM15+FPBTYN10F5/kSUlWNecffgHczu8uj/0Jdx2m+QawXZLXJpnffJA/EzizGRb7HPDm5sTwHvTON0zmvvSGpjYBC4Bj6H0jkAYyCDRbvRM4Fzgvyc+Bf6V3cnYY+wNXNtu9HXhBVW1uxtdfQm+4ZhOwN3BgS5db7kzvxPTNwNX0hnpOaNadAjyhGfZa3XzY7w8cRC+YjgNeWFVXNf1fTm/4aBNwKnAGvfsuJvI5eucurmqOfWOzrTSQN5RJc0yS9wALq+rlo65F2wZvKJNmuWY4qIDLgScDh9G7AkqaFgaBNPvdDzid3hVE1wNvraovjLYkbUscGpKkjvNksSR13JwbGlq0aFEtW7Zs1GVI0pxy4YUX3lhViwetm3NBsGzZMtatm/bLviVpm5bk2onWOTQkSR1nEEhSxxkEktRxBoEkdZxBIEkdZxBIUse1FgRJPpjkhiSXTrA+SU5Isr55RuuwM0tKkqZRm98IPgTsO8n6/eg9T3Y5veewntRiLZKkCbQWBFX1deA/J+lyIPDh5klO5wM7J3lQW/VIkgYb5Z3Fu3LX56xuaNp+PL5jkiPofWtgt93GP9FveMuO+n8D26859jlbvM+2WOv0myt1wtypda7UCdY6mVGeLB70/NSBU6FW1SlVtaqqVi1ePHCqDEnSFhplEGzgrg/hXkLvId6SpBk0yiBYAxzWXD30JOBnVXW3YSFJUrtaO0eQ5AzgacCiJBuAo4HtAarqZGAt8GxgPfBL4PC2apEkTay1IKiqSZ+pWr1Ho72yreNLkobjncWS1HEGgSR1nEEgSR1nEEhSxxkEktRxBoEkdZxBIEkdZxBIUscZBJLUcQaBJHWcQSBJHWcQSFLHGQSS1HEGgSR1nEEgSR1nEEhSxxkEktRxBoEkdZxBIEkdZxBIUscZBJLUcQaBJHWcQSBJHWcQSFLHGQSS1HEGgSR1nEEgSR1nEEhSxxkEktRxBoEkdZxBIEkdZxBIUse1GgRJ9k1yZZL1SY4asH63JF9JclGSS5I8u816JEl311oQJJkHnAjsB6wADkmyYly3vwc+UVUrgYOB97VVjyRpsDa/EewJrK+qq6vqdmA1cOC4PgXs1Ly+H7CxxXokSQO0GQS7Atf1LW9o2vr9A3Bokg3AWuBVg3aU5Igk65Ks27RpUxu1SlJntRkEGdBW45YPAT5UVUuAZwOnJ7lbTVV1SlWtqqpVixcvbqFUSequNoNgA7C0b3kJdx/6eQnwCYCq+hawEFjUYk2SpHHaDIILgOVJdk+ygN7J4DXj+vwHsDdAkkfSCwLHfiRpBrUWBFW1GTgSOAe4gt7VQZclOSbJAU23vwFeluRi4AzgL6pq/PCRJKlF89vceVWtpXcSuL/tTX2vLwf2arMGSdLkvLNYkjrOIJCkjjMIJKnjDAJJ6jiDQJI6ziCQpI4zCCSp4wwCSeo4g0CSOs4gkKSOMwgkqeMMAknqOINAkjrOIJCkjjMIJKnjDAJJ6jiDQJI6ziCQpI4zCCSp4wwCSeo4g0CSOs4gkKSOMwgkqeMMAknqOINAkjrOIJCkjjMIJKnjDAJJ6jiDQJI6ziCQpI4zCCSp4wwCSeq4oYIgyVlJnpPkHgVHkn2TXJlkfZKjJujzgiSXJ7ksycfuyf4lSVtv2A/2k4A/A/49ybFJHjHVBknmAScC+wErgEOSrBjXZznwBmCvqnoU8Np7UrwkaesNFQRVdW5V/TnweOAa4EtJ/jXJ4Um2n2CzPYH1VXV1Vd0OrAYOHNfnZcCJVXVTc5wbtuRNSJK23NBDPUl2Af4CeClwEfAeesHwpQk22RW4rm95Q9PW72HAw5J8M8n5SfYdth5J0vSYP0ynJJ8CHgGcDjy3qn7crPp4knUTbTagrQYcfznwNGAJ8I0ke1TVzeOOfwRwBMBuu+02TMmSpCEN+43g1KpaUVVvHwuBJPcCqKpVE2yzAVjat7wE2Digz2er6o6q+iFwJb1guIuqOqWqVlXVqsWLFw9ZsiRpGMMGwVsHtH1rim0uAJYn2T3JAuBgYM24Pp8B/gQgySJ6Q0VXD1mTJGkaTDo0lOSB9Mb1d0iykt8N9+wE7DjZtlW1OcmRwDnAPOCDVXVZkmOAdVW1pln3zCSXA3cCr6+qn27VO5Ik3SNTnSN4Fr0TxEuA4/rafw783VQ7r6q1wNpxbW/qe13A65o/kqQRmDQIquo04LQkz6+qs2aoJknSDJpqaOjQqvoIsCzJ3X5rr6rjBmwmSZpDphoaunfz930GrBt/KagkaQ6aamjo/c3Lc6vqm/3rkuzVWlWSpBkz7OWj7x2yTZI0x0x1juDJwB8Ci8edI9iJ3iWhkqQ5bqpzBAvonR+YD9y3r/0W4KC2ipIkzZypzhF8Dfhakg9V1bUzVJMkaQYNNekccK8kpwDL+repqqe3UZQkaeYMGwRnAicDp9KbCkKStI0YNgg2V9VJrVYiSRqJYS8f/VySVyR5UJLfH/vTamWSpBkx7DeCFzd/v76vrYCHTG85kqSZNlQQVNXubRciSRqNYb8RkGQPYAWwcKytqj7cRlGSpJkz7DOLj6b3XOEV9J4vsB/wL4BBIElz3LAniw8C9gaur6rDgccC92qtKknSjBk2CG6rqt8Am5PsBNyAJ4olaZsw7DmCdUl2Bv4PcCFwK/Cd1qqSJM2YYa8aekXz8uQkXwB2qqpL2itLkjRThj1Z/NRBbVX19ekvSZI0k4YdGuq/kWwhsCe9ISInnZOkOW7YoaHn9i8nWQq8s5WKJEkzatirhsbbAOwxnYVIkkZj2HME76U3txD0wmMlcHFbRUmSZs6w5wh+wO+eUfxT4Iyq+mY7JUmSZtJUD6/fHngXcBhwDRDg/sB7gW8mWVlVF7VdpCSpPVN9I3g3sCPw4Kr6OUBzZ/E/JTkJ2BdwZlJJmsOmCoJnA8urauz8AFV1S5K/Bm6kN/mcJGkOm+qqod/0h8CYqroT2FRV57dTliRppkwVBJcnOWx8Y5JDgSvaKUmSNJOmGhp6JfCpJH9J707iAp4A7AA8r+XaJEkzYNIgqKofAU9M8nTgUfSuGjq7qr48E8VJkto31J3FVXVeVb23qk64JyGQZN8kVyZZn+SoSfodlKSSrBp235Kk6bGlU0xMKck84ER6VxatAA5JsmJAv/sCrwa+3VYtkqSJtRYE9GYoXV9VV1fV7cBq4MAB/d5CbwK7X7VYiyRpAm0Gwa7AdX3LG5q230qyElhaVZ+fbEdJjkiyLsm6TZs2TX+lktRhbQZBBrT99p6EJNsBxwN/M9WOquqUqlpVVasWL148jSVKktoMgg3A0r7lJcDGvuX70pvK+qtJrgGeBKzxhLEkzaw2g+ACYHmS3ZMsAA4G1oytrKqfVdWiqlpWVcuA84EDqmpdizVJksZpLQiqajNwJHAOvbuQP1FVlyU5JskBbR1XknTPDPs8gi1SVWuBtePa3jRB36e1WYskabA2h4YkSXOAQSBJHWcQSFLHGQSS1HEGgSR1nEEgSR1nEEhSxxkEktRxBoEkdZxBIEkdZxBIUscZBJLUcQaBJHWcQSBJHWcQSFLHGQSS1HEGgSR1nEEgSR1nEEhSxxkEktRxBoEkdZxBIEkdZxBIUscZBJLUcQaBJHWcQSBJHWcQSFLHGQSS1HEGgSR1nEEgSR1nEEhSxxkEktRxrQZBkn2TXJlkfZKjBqx/XZLLk1yS5MtJHtxmPZKku2stCJLMA04E9gNWAIckWTGu20XAqqp6DPBJ4J1t1SNJGqzNbwR7Auur6uqquh1YDRzY36GqvlJVv2wWzweWtFiPJGmANoNgV+C6vuUNTdtEXgKcPWhFkiOSrEuybtOmTdNYoiSpzSDIgLYa2DE5FFgFvGvQ+qo6papWVdWqxYsXT2OJkqT5Le57A7C0b3kJsHF8pyT7AP8L+OOq+nWL9UiSBmjzG8EFwPIkuydZABwMrOnvkGQl8H7ggKq6ocVaJEkTaC0IqmozcCRwDnAF8ImquizJMUkOaLq9C7gPcGaS7yVZM8HuJEktaXNoiKpaC6wd1/amvtf7tHl8SdLUvLNYkjrOIJCkjjMIJKnjDAJJ6jiDQJI6ziCQpI4zCCSp4wwCSeo4g0CSOs4gkKSOMwgkqeMMAknqOINAkjrOIJCkjjMIJKnjDAJJ6jiDQJI6ziCQpI4zCCSp4wwCSeo4g0CSOs4gkKSOMwgkqeMMAknqOINAkjrOIJCkjjMIJKnjDAJJ6jiDQJI6ziCQpI4zCCSp4wwCSeo4g0CSOq7VIEiyb5Irk6xPctSA9fdK8vFm/beTLGuzHknS3bUWBEnmAScC+wErgEOSrBjX7SXATVX1UOB44B1t1SNJGqzNbwR7Auur6uqquh1YDRw4rs+BwGnN608CeydJizVJksZJVbWz4+QgYN+qemmz/CLgiVV1ZF+fS5s+G5rlq5o+N47b1xHAEc3iw4Ert7CsRcCNU/aaPeZSvXOpVphb9c6lWmFu1TuXaoWtq/fBVbV40Ir5W17PlAb9Zj8+dYbpQ1WdApyy1QUl66pq1dbuZ6bMpXrnUq0wt+qdS7XC3Kp3LtUK7dXb5tDQBmBp3/ISYONEfZLMB+4H/GeLNUmSxmkzCC4AlifZPckC4GBgzbg+a4AXN68PAs6rtsaqJEkDtTY0VFWbkxwJnAPMAz5YVZclOQZYV1VrgA8ApydZT++bwMFt1dPY6uGlGTaX6p1LtcLcqncu1Qpzq965VCu0VG9rJ4slSXODdxZLUscZBJLUcZ0Jgqmmu5hNknwwyQ3NfRazWpKlSb6S5IoklyV5zahrmkiShUm+k+TiptY3j7qmYSSZl+SiJJ8fdS2TSXJNku8n+V6SdaOuZypJdk7yySQ/aP79PnnUNQ2S5OHNz3Tszy1JXjutx+jCOYJmuot/A55B75LVC4BDqurykRY2gSRPBW4FPlxVe4y6nskkeRDwoKr6bpL7AhcC/202/mybu9bvXVW3Jtke+BfgNVV1/ohLm1SS1wGrgJ2qav9R1zORJNcAq8bfEDpbJTkN+EZVndpc2bhjVd086rom03yW/YjejbfXTtd+u/KNYJjpLmaNqvo6c+R+iqr6cVV9t3n9c+AKYNfRVjVY9dzaLG7f/JnVvwklWQI8Bzh11LVsS5LsBDyV3pWLVNXtsz0EGnsDV01nCEB3gmBX4Lq+5Q3M0g+ruayZPXYl8O3RVjKxZpjle8ANwJeqatbW2vjfwN8Cvxl1IUMo4ItJLmymhZnNHgJsAv5vM+x2apJ7j7qoIRwMnDHdO+1KEAw1lYW2XJL7AGcBr62qW0Zdz0Sq6s6qehy9O933TDJrh96S7A/cUFUXjrqWIe1VVY+nN+PwK5shztlqPvB44KSqWgn8Apjt5w4XAAcAZ073vrsSBMNMd6Et1Iy3nwV8tKo+Nep6htEMA3wV2HfEpUxmL+CAZux9NfD0JB8ZbUkTq6qNzd83AJ+mNyQ7W20ANvR9I/wkvWCYzfYDvltVP5nuHXclCIaZ7kJboDkB+wHgiqo6btT1TCbJ4iQ7N693APYBfjDaqiZWVW+oqiVVtYzev9nzqurQEZc1UJJ7NxcL0AyxPBOYtVe9VdX1wHVJHt407Q3MugscxjmEFoaFoN3ZR2eNiaa7GHFZE0pyBvA0YFGSDcDRVfWB0VY1ob2AFwHfb8beAf6uqtaOsKaJPAg4rbnyYjvgE1U1qy/JnEMeAHy6eZzIfOBjVfWF0ZY0pVcBH21+ObwaOHzE9UwoyY70rnp8eSv778Llo5KkiXVlaEiSNAGDQJI6ziCQpI4zCCSp4wwCSeq4Tlw+qm1bkl2ALzeLDwTupDd9AMCezfxSs1rzzO4bq2rnUdei7vHyUW1TkvwDcGtV/dMMH3d+VW3emu0xCDQiDg1pm5bkxc0zCL6X5H1JtksyP8nNSY5tnk3wrST3b/ofnOTSpv0rTdsOSU5r5tr/7tgcOklemmR185yAs8cd9939E68leWuS1yTZKcl5zX4uaeYTGl/zPkk+07d8cpJDm9dPSPK1ZmK3s5M8oGn/H0kub+qetdNQaHYyCLTNaiaUex7wh81Ec/PpTdUAcD/ga1X1WOBbwF827UcDezftz2vaXg3cXlWPpncX9enN3agATwZeVFXPGHf41cAL+5b/lN5kYbcBBzaTs+0DHH8P3s+9gPcAz6+qPwA+ArylWf23wOOauo8cdp8SeI5A27Z9gCcA65qpD3bgd9OR31ZVY7/FXwj8UfP6m8CHk5wJjE2g9xTgXQBVdVmSjcBDm3VfrKqbxh+4qi5I7+ltD6A3yeH1VbWxCZB3JHkKvamllyZZBAwzF/4jgUcB5zbvZx69ydMALgM+kuSzwGcGby4NZhBoWxZ680q98S6NvfH4/hPId/K7/xdeBjwR2B+4OMljGDyN+ZhfTLLuLOD5wDJ63xAADqP3beTxzRxYG4CF47bbzF2/rY+tD3BJVf0Rd/cs4I/pPXDp75PsUVV3TlKb9FsODWlbdi7wguY3bpLskmS3KbZ5SPPoyjcCN9F7gNHXgT9v9vFIepPXrR/i+KvpDUX9d3qhAL0QuKEJgWcw+AFJ1wKPSrIgye8BT2/aLwd2TbJnU8uCJI9qJtFbUlXnAa8HFgM7DlGfBPiNQNuwqvp+eg+oPzfJdsAdwF8x+bMojk+yO73fvr9YVZcmuQp4f5LvN/s4rKpub4ZnJjv+xUkWAz9s5ugHOB34XHoPd/8u8O8Dtvthc7L4+/SetT32KNBfJzkIOKGZ8nk+8G56ofSxpm074B3NY0OloXj5qCR1nENDktRxBoEkdZxBIEkdZxBIUscZBJLUcQaBJHWcQSBJHff/AcKf83GkDCJCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 <= rank(T) <= 4\n",
      "\n",
      "Generic rank of the tensor space of T = 2\n",
      "\n",
      "Computing multilinear rank...\n",
      "------------------------------------\n",
      "multirank(T) = (2, 2, 2)\n",
      "|T - (U_1, ..., U_3)*S|/|T| = 5.105819006508713e-16\n",
      "\n",
      "Computing rank...\n",
      "Start searching for rank\n",
      "Stops at r = 4  or less\n",
      "-----------------------------\n",
      "Testing r = 3\n",
      "rank(T) = 3\n",
      "|T - T_approx|/|T| = 7.240847050511626e-16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's see some information about T.\n",
    "tfx.disp.infotens(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the CPD\n",
    "\n",
    "Now let's turn to the most important tool of Tensor Fox, the computation of the CPD. As the previous function hinted, $T$ should have rank 3. We can compute the corresponding CPD with the function **cpd**. Since Tensor Fox is compiled, the first run is slower than the remaining ones. Don't forget that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X =\n",
      " [[-1.23404281  0.99336328 -0.96884134]\n",
      " [-0.71017725  1.92714892 -0.65167689]]\n",
      "\n",
      "Y =\n",
      " [[ 0.49686304 -1.43359926  1.13471233]\n",
      " [ 1.33429401 -1.62648908 -0.27525304]]\n",
      "\n",
      "Z =\n",
      " [[ 0.63072384 -1.08729772  1.0566873 ]\n",
      " [-1.27647985 -1.87575511 -0.4967376 ]]\n",
      "\n",
      "T_approx =\n",
      "[[2.22044605e-15 1.00000000e+00]\n",
      " [2.00000000e+00 3.00000000e+00]]\n",
      "\n",
      "[[4. 5.]\n",
      " [6. 7.]]\n",
      "\n",
      "|T - T_approx|/|T| = 9.832124790413887e-16\n"
     ]
    }
   ],
   "source": [
    "# Compute the CPD of T, assuming T has rank 3.\n",
    "R = 3\n",
    "factors, output = tfx.cpd(T, R)\n",
    "\n",
    "# 'factors' is the list of the factor matrices associated with the CPD.\n",
    "X = factors[0]\n",
    "Y = factors[1]\n",
    "Z = factors[2]\n",
    "\n",
    "# Show the CPD computed. \n",
    "print('X =\\n', X)\n",
    "print()\n",
    "print('Y =\\n', Y)\n",
    "print()\n",
    "print('Z =\\n', Z)\n",
    "print()\n",
    "\n",
    "# Show the coordinate representation of this CPD.\n",
    "print('T_approx =')\n",
    "T_approx = tfx.cnv.cpd2tens(factors)\n",
    "tfx.disp.showtens(T_approx)\n",
    "\n",
    "# Show relative error of this approximation.\n",
    "print('|T - T_approx|/|T| =', output.rel_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it is convenient to use normalized factors, we can convert everything to the format $\\Lambda, X, Y, Z$, where the columns of $X, Y, Z$ are unit norm and their magnitudes are passed to the central tensor $\\Lambda \\in \\mathbb{R}^{R \\times R \\times R}$. Since $\\Lambda$ is a diagonal tensor, we can store its values as a unidimensional array of size $R$. This is made such that\n",
    "$$T \\approx \\sum_{r=1}^R \\Lambda_r \\ X_{:, r} \\otimes Y_{:, r} \\otimes Z_{:, r}.$$\n",
    "\n",
    "We denote this relation as $T \\approx (X, Y, Z) \\cdot \\Lambda$, the multilinear multiplication. With a simple command we can obtain this factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda =\n",
      " [ 2.88635134 10.19154763  1.59185864]\n",
      "\n",
      "X =\n",
      " [[-0.86672334  0.45817149 -0.82975745]\n",
      " [-0.49878918  0.88886382 -0.55812416]]\n",
      "\n",
      "Y =\n",
      " [[ 0.34896909 -0.66122265  0.97181651]\n",
      " [ 0.93713423 -0.75018971 -0.23573856]]\n",
      "\n",
      "Z =\n",
      " [[ 0.4429855  -0.50149711  0.90499252]\n",
      " [-0.89652878 -0.86515932 -0.42542748]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Lambda, factors = tfx.cnv.normalize(factors)\n",
    "X = factors[0]\n",
    "Y = factors[1]\n",
    "Z = factors[2]\n",
    "\n",
    "print('Lambda =\\n', Lambda)\n",
    "print()\n",
    "print('X =\\n', X)\n",
    "print()\n",
    "print('Y =\\n', Y)\n",
    "print()\n",
    "print('Z =\\n', Z)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some submodules to pay attention TensorFox. In particular, *cnv* refers to the *Conversion* submodule, which is responsible for converting objects with a certain format to another format. We will see more about that in the next lessons. \n",
    "\n",
    "In this lesson we used the submodules *cnv, disp*. Note that we didn't define these alias, they are available automatically. Below we list all submodules and their corresponding aliases:\n",
    "\n",
    " - Alternating_Least_Squares: *als*\n",
    " \n",
    " - Auxiliar: *aux*\n",
    " \n",
    " - Compression: *cmpr*\n",
    " \n",
    " - Conversion: *cnv*\n",
    " \n",
    " - Critical: *crt*\n",
    " \n",
    " - Display: *disp*\n",
    " \n",
    " - GaussNewton: *gn*\n",
    " \n",
    " - Initialization: *init*\n",
    " \n",
    " - MultilinearAlgebra: *mlinalg*\n",
    " \n",
    " Using these aliases is not mandatory. One can choose between $\\verb|tfx.cnv.normalize(factors)|$ and $\\verb|tfx.Conversion.normalize(factors)|$. Both commands works just fine. In each submodule there are functions not supposedly to be used directly by the user, they are just subroutines of other important functions. The functions expected to be used directly are listed in the [README](https://github.com/felipebottega/Tensor-Fox/blob/master/README.md) file (see the section *Structure of Tensor Fox*). \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
