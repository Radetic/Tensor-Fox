{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Condition number\n",
    "\n",
    "Let $T \\in \\mathbb{R}^{I_1 \\times \\ldots \\times I_L}$ be a tensor and suppose we want to find a rank-$R$ approximation $\\tilde{T} = (W^{(1)}, \\ldots, W^{(L)}) \\cdot I$ for $T$. Usually any CPD solver (Tensor Fox included) tries to find an approximation that minimizes the error function\n",
    "\n",
    "$$F(W^{(1)}, \\ldots, W^{(L)}) = \\frac{1}{2} \\| T - \\tilde{T} \\|^2.$$\n",
    "\n",
    "Note that $\\tilde{T}$ lies in the input space, not the output space. Therefore we are actually minimizing the backward error of the problem. In order to have a small forward error we also need that the solution is well conditioned. In this case the forward error is defined as\n",
    "\n",
    "$$\\| (T_1, \\ldots, T_R) - (\\tilde{T}_1, \\ldots, \\tilde{T}_R) \\| = \\min_{s \\in \\mathfrak{S}_R} \\sqrt{ \\|T_1 - \\tilde{T}_{s(1)} \\|^2 + \\ldots + \\| T_R - \\tilde{T}_{s(R)}) \\|^2 },$$\n",
    "where $\\mathfrak{S}_R$ is the group of $R$ permutations, $T = \\sum_{r=1}^R$ and $\\tilde{T} = \\sum_{r=1}^R \\tilde{T}_r$. In other words, the forward error is the accumulated error of the rank one terms. Furthermore, it is necessary to minimize over all possible permutations because the CPD computed may have the rank one terms permuted in a different order of the original tensor.\n",
    "\n",
    "The condition number associated to the problem of the CPD computation is then\n",
    "\n",
    "$$\\kappa(T_1, \\ldots, T_R) = \\lim_{\\epsilon \\to 0} \\max_{\\tilde{T} \\in D(T, \\epsilon, R)} \\frac{ \\| (T_1, \\ldots, T_R) - (\\tilde{T}_1, \\ldots, \\tilde{T}_R) \\| }{ \\| T - \\tilde{T} \\| }, $$\n",
    "where $D(T, \\epsilon, R) \\subset \\mathbb{R}^{I_1 \\times \\ldots \\times I_L}$ is the intersection between the $\\epsilon$-ball centered at $T$ and the set of rank-$R$ tensors. \n",
    "\n",
    "For more about the theory described here I recommend reading the following articles:\n",
    "\n",
    "[1] P. Breiding and . Vannieuwenhoven, *A Riemannian Trust Region Method for the Canonical Tensor Rank Approximation Problem*, SIAM J. Optim., 28(3), 2435-2465.\n",
    "\n",
    "[2] P. Breiding and N. Vannieuwenhoven, *The Condition Number of Join Decompositions*, arXiv:1611.08117v3 (2018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import TensorFox as tfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random rank-R tensor. Tensor Fox has a function for this purpose.\n",
    "R = 5\n",
    "dims = [20, 30, 40] \n",
    "T, orig_factors = tfx.aux.gen_rand_tensor(dims, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond(T) = 2.052731923992039\n"
     ]
    }
   ],
   "source": [
    "# First let's see what is the condition number of the original tensor.\n",
    "cond = tfx.mlinalg.cond(orig_factors)\n",
    "print('cond(T) =', cond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random tensors generated this way (i.e., their factor matrices have entries draw from the standard Gaussian distribution) usually have low condition numbers. Remember that condition numbers are useful to bound the forward error with the classic rule of thumb in numerical analysis:\n",
    "\n",
    "$$\\underbrace{\\| (T_1, \\ldots, T_R) - (\\tilde{T}_1, \\ldots, \\tilde{T}_R) \\|}_{\\text{forward error}} \\leq \\underbrace{\\kappa(T_1, \\ldots, T_R)}_{\\text{condition number}} \\cdot \\underbrace{\\| T - \\tilde{T} \\|}_{\\text{backward error}}.$$\n",
    "\n",
    "Now we compute an approximated CPD for $T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute CPD.\n",
    "factors, T_approx, output = tfx.cpd(T, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backward error = 0.00047030291857279007\n",
      "cond(T_approx)= 2.052731861398798\n"
     ]
    }
   ],
   "source": [
    "# Display backward error and condition number of the approximation.\n",
    "backward_error = output.rel_error * np.linalg.norm(T)\n",
    "condition_number = tfx.mlinalg.cond(factors)\n",
    "print('backward error =', backward_error)\n",
    "print('cond(T_approx)=', condition_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the backward error is of order $\\mathcal{O}(10^{-4})$ and that the condition number is very close to the original one, which indicates the solution is indeed good. With these two values we can bound the forward error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward error <= 2.052731861398798 * 0.00047030291857279007 = 0.0009654057854632108\n"
     ]
    }
   ],
   "source": [
    "print('forward error <=', condition_number, '*', backward_error, '=', condition_number*backward_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compute the actual forward error of this solution. We remark that the following function generates $1000$ random permutations and keep the best one, so the forward error showed is just an estimate. To get better estimates you can set the keyword *trials* to a higher value. However be warned that this function is costly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward error = 0.0004702711368125619\n"
     ]
    }
   ],
   "source": [
    "# new_factors are the factors after permutation, and idx is the permutation index.\n",
    "forward_error, new_factors, idx = tfx.mlinalg.forward_error(orig_factors, factors, trials=10000)\n",
    "print('forward error =', forward_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
